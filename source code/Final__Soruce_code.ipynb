{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7n6O0JF-h8AT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4oFS88qg3vF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import glob\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Data Manipulation and Processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Machine Learning & Evaluation Metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    precision_recall_curve,\n",
        "    average_precision_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    log_loss\n",
        ")\n",
        "\n",
        "# 5. Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Architectures\n",
        "from tensorflow.keras.applications import (\n",
        "    ResNet50,\n",
        "    ResNet50V2,\n",
        "    DenseNet121\n",
        ")\n",
        "\n",
        "# Model Construction (Sequential, Functional, & Ensemble Layers)\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Dense,\n",
        "    GlobalAveragePooling2D,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    MaxPooling2D,\n",
        "    Conv2D,\n",
        "    BatchNormalization,\n",
        "    Rescaling,\n",
        "    Average,\n",
        "    Concatenate\n",
        ")\n",
        "\n",
        "# Optimizers & Loss\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
        "\n",
        "# Keras Metrics (For training monitoring)\n",
        "from tensorflow.keras.metrics import (\n",
        "    BinaryAccuracy,\n",
        "    Precision,\n",
        "    Recall,\n",
        "    AUC\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping,\n",
        "    ReduceLROnPlateau,\n",
        "    ModelCheckpoint\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load and Prepare Data"
      ],
      "metadata": {
        "id": "5Aqqw6JgjYOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  **Check Directories**: First, we verify that both the original RSNA competition dataset (containing labels) and the PNG image dataset are attached to the notebook.\n",
        "2.  **Load Labels**: We load the `stage_2_train_labels.csv` file.\n",
        "3.  **Create Classification DataFrame**: We create a clean `df_class` DataFrame with one unique row per patient, linking each `patientId` to its corresponding `.png` filename.\n"
      ],
      "metadata": {
        "id": "C2dwXbMQjb-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not BASE_DIR.exists() :\n",
        "    print(f\" dataset not foundnot found.\")\n",
        "\n",
        "else:\n",
        "    print(f\"dataset found.\")\n",
        "\n",
        "    labels_path = BASE_DIR / 'stage_2_train_labels.csv'\n",
        "    if labels_path.exists():\n",
        "        df_labels = pd.read_csv(labels_path)\n",
        "        print(f\"\\nSuccess! RSNA Labels loaded. Shape: {df_labels.shape}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "NkShMZG6jbn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Understand the Dataset Of The Labels With Basic EDA**"
      ],
      "metadata": {
        "id": "8Uvb97tyjx7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels.head()"
      ],
      "metadata": {
        "id": "19j4I__ij3aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Null Value Check\")\n",
        "print(\"-\" * 60)\n",
        "print(df_labels.isnull().sum())\n",
        "\n",
        "print(\"\\n Duplicate Check\")\n",
        "print(\"-\" * 60)\n",
        "dup_count = df_labels.duplicated().sum()\n",
        "print(df_labels.duplicated('patientId').sum())\n",
        "print(f\"Total duplicate rows: {dup_count}\")\n",
        "\n",
        "print(\"\\nℹ Basic Data Information\")\n",
        "print(\"-\" * 60)\n",
        "df_labels.info()\n",
        "\n",
        "print(\"\\n Summary Statistics (Numerical Columns)\")\n",
        "print(\"-\" * 60)\n",
        "display(df_labels.describe())\n"
      ],
      "metadata": {
        "id": "-E1DP2Zaj5F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = df_labels['Target'].value_counts().sort_index()\n",
        "print(df_labels['Target'].value_counts())\n",
        "\n",
        "class_counts.plot(kind='bar', color=['teal', 'indigo'])\n",
        "plt.title(\"Pneumonia vs Normal Cases\")\n",
        "plt.xlabel(\"Target (0=Normal, 1=Pneumonia)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aqfNWSKFj9jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.  **Verify Files**: We cross-reference this DataFrame with the actual files in the `PNG_DIR` to ensure we only work with images that exist, preventing \"File Not Found\" errors during training."
      ],
      "metadata": {
        "id": "mQ1rmuv3kITJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_class = df_labels.drop_duplicates('patientId')[['patientId', 'Target']].copy()\n",
        "df_class['filename'] = df_class['patientId'].apply(lambda x: f\"{x}.png\")\n",
        "df_class['Target'] = df_class['Target'].astype(str)\n",
        "\n",
        "df_class['filepath'] = df_class['filename'].apply(lambda f: PNG_DIR / f)\n",
        "df_class['file_exists'] = df_class['filepath'].apply(lambda p: p.exists())\n",
        "\n",
        "df_class = df_class[df_class['file_exists']].copy().reset_index(drop=True)\n",
        "\n",
        "print(\"Dataframe ready for EDA\")\n"
      ],
      "metadata": {
        "id": "iAZJ3uxgkDgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_class.head()"
      ],
      "metadata": {
        "id": "sRYrqKtQkSqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Exploratory Data Analysis (EDA)\n",
        "\n",
        "With the data successfully loaded, we now explore its characteristics.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kqoIxAgekUT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  **Class Distribution**: We visualize the count of \"Normal\" vs. \"Pneumonia\" cases to understand the class imbalance in the dataset."
      ],
      "metadata": {
        "id": "AslEOdT6kV6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='Target', data=df_class, palette='viridis')\n",
        "plt.title('Distribution of Pneumonia Cases (0 = Normal, 1 = Pneumonia)', fontsize=14)\n",
        "plt.xlabel('Class', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "print(\"Class Counts:\")\n",
        "print(df_class['Target'].value_counts())\n",
        "\n"
      ],
      "metadata": {
        "id": "92PrxqIpkZLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  **Metadata Extraction**: We extract valuable metadata (Age, Sex, View Position) from the original DICOM files. This step is crucial for conducting a fairness analysis later to ensure the model performs equitably across different demographic groups."
      ],
      "metadata": {
        "id": "LzshCrYgkbG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nExtracting metadata from DICOM\")\n",
        "\n",
        "ages, sexes, view_positions = [], [], []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for patient_id in tqdm(df_class['patientId']):\n",
        "    dcm_path = DICOM_DIR / f\"{patient_id}.dcm\"\n",
        "    dcm_data = pydicom.dcmread(dcm_path, stop_before_pixels=True)\n",
        "    ages.append(dcm_data.PatientAge)\n",
        "    sexes.append(dcm_data.PatientSex)\n",
        "    view_positions.append(dcm_data.ViewPosition)\n",
        "\n",
        "df_class['Age'] = ages\n",
        "df_class['Sex'] = sexes\n",
        "df_class['ViewPosition'] = view_positions\n",
        "df_class['Age'] = df_class['Age'].astype(int)\n",
        "df_class['AgeGroup'] = pd.cut(df_class['Age'], bins=[0, 18, 40, 60, 150], labels=['Child', 'Young Adult', 'Adult', 'Senior'])\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed = end_time - start_time\n",
        "\n"
      ],
      "metadata": {
        "id": "5QGQ8AUDkbn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  **Metadata Distribution**: We visualize the distribution of patients by sex and age group."
      ],
      "metadata": {
        "id": "VBt0gyY3krDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "sns.countplot(x='Sex', data=df_class, ax=axes[0], palette='magma')\n",
        "axes[0].set_title('Distribution by Sex')\n",
        "sns.countplot(x='AgeGroup', data=df_class, ax=axes[1], palette='plasma')\n",
        "axes[1].set_title('Distribution by Age Group')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h0vlUykykrmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Visualizing Image Examples\n",
        "\n",
        "To get a better understanding of the data, let's look at some example chest X-ray images from our dataset. We will display a few samples for both **Normal** (Target = 0) and **Pneumonia** (Target = 1) cases. This helps in visually confirming the characteristics the model will learn to distinguish."
      ],
      "metadata": {
        "id": "vWXypq3Sk5ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image_samples(df, target, num_samples=5, figsize=(20, 5)):\n",
        "    sample_df = df[df['Target'] == str(target)].sample(num_samples, random_state=42)\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=figsize)\n",
        "    fig.suptitle(f'Sample Images: {\"Pneumonia\" if target == 1 else \"Normal\"} Cases', fontsize=16)\n",
        "\n",
        "    for i, (idx, row) in enumerate(sample_df.iterrows()):\n",
        "        img_path = row['filepath']\n",
        "        img = Image.open(img_path).convert('RGB') # Convert to RGB for consistency\n",
        "        axes[i].imshow(img, cmap='gray')\n",
        "        axes[i].set_title(f\"Patient: {row['patientId'][:8]}...\", fontsize=10)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "        # If it's a pneumonia case, draw the bounding boxes\n",
        "        if target == 1:\n",
        "            bboxes = df_labels[df_labels['patientId'] == row['patientId']]\n",
        "            for _, box_row in bboxes.iterrows():\n",
        "                if not np.isnan(box_row['x']):\n",
        "                    # Create a Rectangle patch\n",
        "                    rect = patches.Rectangle(\n",
        "                        (box_row['x'], box_row['y']),\n",
        "                        box_row['width'],\n",
        "                        box_row['height'],\n",
        "                        linewidth=2,\n",
        "                        edgecolor='r',\n",
        "                        facecolor='none'\n",
        "                    )\n",
        "\n",
        "                    axes[i].add_patch(rect)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#Normal cases (Target = 0)\n",
        "plot_image_samples(df_class, target=0, num_samples=5)\n",
        "\n",
        "#Pneumonia cases (Target = 1)\n",
        "plot_image_samples(df_class, target=1, num_samples=5)"
      ],
      "metadata": {
        "id": "G0UtmM1ok56w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Data Preprocessing & Splitting\n",
        "\n",
        "This is the final preparation step before we build our model. We split the master DataFrame (`df_class`) into training and validation sets.\n",
        "\n",
        "- **Stratification**: We use the `stratify` option to ensure that the proportion of normal-to-pneumonia cases is the same in both the training (`df_train`) and validation (`df_val`) sets. This is a critical best practice for imbalanced datasets as it leads to more reliable model evaluation."
      ],
      "metadata": {
        "id": "EYrwzS_IlCYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_test_split(\n",
        "    df_class,\n",
        "    test_size=0.2, # Using 20% of the data for validation\n",
        "    random_state=42,\n",
        "    stratify=df_class['Target'] # Stratify ensures similar class distribution in both sets\n",
        ")\n",
        "\n",
        "print(f\"\\nData successfully split:\")\n",
        "print(f\"Training set size:   {len(df_train)}\")\n",
        "print(f\"Validation set size: {len(df_val)}\")\n",
        "print(\"\\nTraining Set Class Distribution:\")\n",
        "print(df_train['Target'].value_counts(normalize=True))\n",
        "print(\"\\nValidation Set Class Distribution:\")\n",
        "print(df_val['Target'].value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "Y1r0WwW9lEFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This helper function takes a dataframe and an ImageDataGenerator instance. It loads a specific image, applies the random transformations defined in the generator, and plots the original image alongside several augmented versions."
      ],
      "metadata": {
        "id": "oKFwuMgVlUro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_augmented_samples(df, datagen, target, num_augments=5, figsize=(20, 5)):\n",
        "\n",
        "    sample_row = df[df['Target'] == str(target)].sample(1).iloc[0]\n",
        "    img_path = sample_row['filepath']\n",
        "    patient_id = sample_row['patientId']\n",
        "\n",
        "    # 2. Load and Prepare the image\n",
        "    original_img = load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "    # Shape becomes (1, 224, 224, 3)\n",
        "    x = img_to_array(original_img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # 3. Setup the Plot\n",
        "    fig, axes = plt.subplots(1, num_augments + 1, figsize=figsize)\n",
        "    fig.suptitle(f\"Augmentation Effects on Patient: {patient_id[:8]}... (Target: {target})\", fontsize=16)\n",
        "\n",
        "    axes[0].imshow(original_img)\n",
        "    axes[0].set_title(\"Original\", fontsize=12, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "\n",
        "    # The .flow() method generates batches indefinitely.\n",
        "    iterator = datagen.flow(x, batch_size=1)\n",
        "\n",
        "    for i in range(num_augments):\n",
        "\n",
        "        batch = next(iterator)\n",
        "\n",
        "        aug_img = batch[0]\n",
        "\n",
        "\n",
        "        axes[i + 1].imshow(aug_img)\n",
        "        axes[i + 1].set_title(f\"Augment {i+1}\", fontsize=10)\n",
        "        axes[i + 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jdTITnndlc0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define the ImageDataGenerator with specific hyperparameters. These settings (rotation, zoom, horizontal flip) determine how the images are mathematically distorted to create new training examples."
      ],
      "metadata": {
        "id": "faIhLb7wlgnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen_viz = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "1R8CJE2-lh24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Visualizing Pneumonia Cases (Target = 1)\n"
      ],
      "metadata": {
        "id": "yfvK9zpflwaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Visualizing Augmentation on a Pneumonia Case (Target=1)...\")\n",
        "\n",
        "plot_augmented_samples(df_class, train_datagen_viz, target=1, num_augments=5)"
      ],
      "metadata": {
        "id": "A4Msdr9Ulx9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Visualizing Normal Cases (Target = 0)\n"
      ],
      "metadata": {
        "id": "FXmjcsOFl8kI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_augmented_samples(df_class, train_datagen_viz, target=0, num_augments=5)"
      ],
      "metadata": {
        "id": "9QPo8SuXl75w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Model Preparation: Data Augmentation & Generators\n",
        "\n",
        "Before we feed our images to the model, we need to process them. We will use Keras's `ImageDataGenerator` for this."
      ],
      "metadata": {
        "id": "CmiPDsxNmFLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Step 1: Define Image Parameters\n",
        "We first set the image size and batch size — these control the shape and number of images fed to the model at once.\n"
      ],
      "metadata": {
        "id": "NcJQIS1zmNeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "KWROGj8emJDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Create Data Augmentation Generator for Training\n",
        "The training generator will apply random transformations (rotation, zoom, flipping, etc.)\n",
        "to make the model more robust and reduce overfitting.\n"
      ],
      "metadata": {
        "id": "zWQfyrk0mUTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255.,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "TImMynxFmV1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Create a Simple Rescaling Generator for Validation\n",
        "Validation data should **not** be augmented — we only rescale pixel values to `[0, 1]`\n",
        "to evaluate the model on clean, unmodified images.\n"
      ],
      "metadata": {
        "id": "0gnA2IVcmX2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_datagen = ImageDataGenerator(rescale=1./255.)"
      ],
      "metadata": {
        "id": "PP7-RT7RmZYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Create Generators That Flow Data from the DataFrame\n",
        "Now, we connect the image file paths and labels to the generators.  \n",
        "The generator will:\n",
        "- Load each image from the directory\n",
        "- Resize it to 224×224\n",
        "- Apply augmentation (for training)\n",
        "- Yield batches automatically during training\n"
      ],
      "metadata": {
        "id": "fMyiJPEJmlXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=df_train,\n",
        "    directory=PNG_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='Target',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    validate_filenames=False\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=df_val,\n",
        "    directory=PNG_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='Target',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False,\n",
        "    validate_filenames=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "A98iw3eWmnVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Calculate Class Weights\n",
        "If one class (e.g., *normal*) has far more samples than the other (e.g., *pneumonia*),\n",
        "we compute **class weights** so the model pays equal attention to both.\n"
      ],
      "metadata": {
        "id": "6qzwpaVAmthR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "print(f\"\\nCalculated Class Weights to handle imbalance: {class_weight_dict}\")\n"
      ],
      "metadata": {
        "id": "B6HDvw-HmtWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7.1.1: Define and Compile the Basic CNN Model\n",
        "\n",
        "We start with a simple Convolutional Neural Network (CNN) architecture to classify chest X-ray images as **Normal** or **Pneumonia**.  \n",
        "This model includes:\n",
        "- Two convolution + pooling layers for feature extraction  \n",
        "- A dense layer for learning complex patterns  \n",
        "- A dropout layer to prevent overfitting  \n",
        "- A sigmoid output layer for binary classification"
      ],
      "metadata": {
        "id": "uvO0JBc5mxka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "FJXm0wpPm0-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "start=time.time()\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weight_dict,  # handle imbalance\n",
        "    verbose=1\n",
        ")\n",
        "end=time.time()\n",
        "elapsed=end-start\n"
      ],
      "metadata": {
        "id": "8Vru2a1dm5GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7.1.4: Visualize Training Performance\n",
        "\n",
        "We plot the training and validation **accuracy** and **loss** over epochs to evaluate model performance.  \n",
        "These plots help us identify:\n",
        "- Overfitting (training accuracy much higher than validation)\n",
        "- Underfitting (both accuracies low)\n",
        "- Convergence (loss decreasing steadily)\n",
        "  "
      ],
      "metadata": {
        "id": "Hr-vY2vmnCs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "K0CIkb89nD1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\n",
        "We use DenseNet121(224) as the feature extractor because its dense connections make it highly efficient at capturing the subtle textural patterns found in X-rays. We add a custom classification head with BatchNormalization and Dropout to prevent overfitting."
      ],
      "metadata": {
        "id": "gxuSoWain0FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_densenet_model(input_shape=(224, 224, 3)):\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze the base model\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # custom classifier head\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)  # High dropout to handle the small dataset size vs model complexity\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return base_model, model\n",
        "\n",
        "base_model, model = build_densenet_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "TlG96nbxn9_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Configure Callbacks\n",
        "We set up callbacks to ensure we save the best version of the model and adjust the learning rate dynamically if the model gets stuck on a plateau."
      ],
      "metadata": {
        "id": "N54vzeguoSG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks_list = [\n",
        "    ModelCheckpoint('best_pneumonia_model.h5', monitor='val_loss', save_best_only=True, mode='min'),\n",
        "\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_lr=1e-7),\n",
        "\n",
        "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "id": "pwI3yPx4oSzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Phase 1: Warm-up Training\n",
        "In this phase, we only train the custom head layers. This allows the random weights of our new dense layers to align with the pre-trained features of the base model without disrupting them."
      ],
      "metadata": {
        "id": "zFLtzLI8oXNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a standard learning rate for the head\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train for a few epochs\n",
        "history_warmup = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "cvuFVEv7oYtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Phase 2: Deep Fine-Tuning\n",
        "Now that the head is stable, we unfreeze the entire model. We recompile with a very low learning rate (1e-5) to gently adjust the pre-trained weights to recognize X-ray specific features (like lung opacity) rather than generic objects."
      ],
      "metadata": {
        "id": "MXqbTD95ogUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze all layers of the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# low learning rate to prevent catastrophic forgetting\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "OwCsrEwbohB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Visualize Combined History\n",
        "This custom plotting function stitches the history from Phase 1 and Phase 2 together, allowing you to see the full training trajectory and the impact of fine-tuning."
      ],
      "metadata": {
        "id": "6ot_WCgtox1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_full_history(h1, h2):\n",
        "    acc = h1.history['accuracy'] + h2.history['accuracy']\n",
        "    val_acc = h1.history['val_accuracy'] + h2.history['val_accuracy']\n",
        "    loss = h1.history['loss'] + h2.history['loss']\n",
        "    val_loss = h1.history['val_loss'] + h2.history['val_loss']\n",
        "\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(acc, label='Train Accuracy')\n",
        "    plt.plot(val_acc, label='Validation Accuracy')\n",
        "    plt.axvline(x=len(h1.history['accuracy'])-0.5, color='green', linestyle='--', label='Fine-Tuning Start')\n",
        "    plt.title('Model Accuracy over Phases')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(loss, label='Train Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.axvline(x=len(h1.history['loss'])-0.5, color='green', linestyle='--', label='Fine-Tuning Start')\n",
        "    plt.title('Model Loss over Phases')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_full_history(history_warmup, history_finetune)"
      ],
      "metadata": {
        "id": "XznVYDDyoxr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Build the Model Architecture\n",
        "We construct the model using ResNet50 pre-trained on ImageNet. We freeze the base layers so they act as a fixed feature extractor and add a custom classification head."
      ],
      "metadata": {
        "id": "R6kLn_M9pKII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ZNMEgy6hpLbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Phase 1: Feature Extraction\n",
        "In this phase, we train only the top layers (the \"head\") that we just added. We use a standard learning rate (1e-4). This allows the random weights of our new layers to converge without disrupting the powerful pre-trained weights in the ResNet base."
      ],
      "metadata": {
        "id": "b1m-2GvEpUCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "L66cGFGdpU0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Phase 2: Fine-Tuning\n",
        "Now that the head is trained, we unfreeze the top 20% of the base model. We switch to a much lower learning rate (1e-5) to gently adapt these pre-trained layers to the specific features of Chest X-rays. We also introduce callbacks for early stopping and learning rate reduction."
      ],
      "metadata": {
        "id": "xKmRPn8NpX6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "# Unfreeze the top 20% of the layers\n",
        "fine_tune_at = int(len(base_model.layers) * 0.8)\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile with a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "history_fine_tune = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    initial_epoch=history.epoch[-1] + 1,\n",
        "    validation_data=validation_generator,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "4lA4r5KTpZ2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Visualize Training History\n",
        "This function concatenates the history from both phases and plots them on a single graph, marking the point where fine-tuning began."
      ],
      "metadata": {
        "id": "OMQcJdRjpmco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, history_fine, initial_epochs=5):\n",
        "    acc = history.history['accuracy'] + history_fine.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy'] + history_fine.history['val_accuracy']\n",
        "    loss = history.history['loss'] + history_fine.history['loss']\n",
        "    val_loss = history.history['val_loss'] + history_fine.history['val_loss']\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(acc, label='Training Accuracy')\n",
        "    plt.plot(val_acc, label='Validation Accuracy')\n",
        "    plt.axvline(x=initial_epochs-1, color='green', linestyle='--', label='Start Fine-Tuning')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.axvline(x=initial_epochs-1, color='green', linestyle='--', label='Start Fine-Tuning')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history, history_fine_tune)"
      ],
      "metadata": {
        "id": "w98h4k-9pncR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Configuration Upgrade\n",
        "We update the global constants. Increasing the image size to 320x320 significantly increases the memory footprint, so we must reduce the batch size (e.g., from 32 to 16) to avoid \"Out of Memory\" (OOM) errors on the GPU"
      ],
      "metadata": {
        "id": "jnYM6-GSqaz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "u08sXFUpqkcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We recreate the ImageDataGenerator objects. We keep the augmentation parameters (rotation, zoom, shifts) active to prevent overfitting, especially now that the model has more pixels (features) to learn from."
      ],
      "metadata": {
        "id": "YA_WuzVKqoEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "jcK7aMz0qtgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we generate the new data flows using the 320x320 target size. These new generator objects (train_generator_320) will be passed to the model during training."
      ],
      "metadata": {
        "id": "RkLXYWW4qziZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator_320 = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=PNG_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='Target',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator_320 = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=PNG_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='Target',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "v5fhtEWyqzMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Rebuild Model Architecture\n",
        "We instantiate a new DenseNet121 with the updated input shape. We attach the exact same classifier head structure as before to ensure the capacity remains sufficient for the task."
      ],
      "metadata": {
        "id": "1fzldYQBrzSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = DenseNet121(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "# classifier head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "predictions = Dense(1, activation=None)(x)\n",
        "\n",
        "final_model_320 = Model(inputs=base_model.input, outputs=predictions)\n",
        "final_model_320.summary()"
      ],
      "metadata": {
        "id": "LzVguh1orz8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Phase 1: Adapter Warm-up\n",
        "Since the DenseNet base weights are for ImageNet (natural images) and our head weights are random, we run a short \"warm-up.\" This aligns the new head with the base features before we unlock the whole network."
      ],
      "metadata": {
        "id": "QAtsvbbgsUDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = SGD(learning_rate=1e-3, momentum=0.9, clipnorm=1.0)\n",
        "\n",
        "final_model_320.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=BinaryCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_warmup_320 = final_model_320.fit(\n",
        "    train_generator_320,\n",
        "    epochs=3,\n",
        "    validation_data=validation_generator_320,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "mSk2shQqsUqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Phase 2: Deep Fine-Tuning\n",
        "Now we unfreeze the entire model. Because we are working with high-resolution medical images, we use an ultra-low learning rate. This allows the pre-trained filters to fine-tune their edge and texture detection specifically for pneumonia opacities without destroying the knowledge they already have."
      ],
      "metadata": {
        "id": "sFz_PBgLsx-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "optimizer_fine = SGD(learning_rate=1e-5, momentum=0.9, clipnorm=1.0)\n",
        "\n",
        "final_model_320.compile(\n",
        "    optimizer=optimizer_fine,\n",
        "    loss=BinaryCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks_list_320 = [\n",
        "    ModelCheckpoint('best_320_densenet.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1),\n",
        "\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7, verbose=1),\n",
        "\n",
        "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "history_fine_320 = final_model_320.fit(\n",
        "    train_generator_320,\n",
        "    epochs=25,\n",
        "    validation_data=validation_generator_320,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=callbacks_list_320,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "Mc5BUkohs0a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Build the Ensemble Partner: ResNet50V2\n",
        " We use ResNet50V2 for this purpose. By training this model on the same 320x320 data, it will learn different feature representations, increasing the ensemble's overall generalization power.\n"
      ],
      "metadata": {
        "id": "rSEM2gZ_tfh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = Rescaling(scale=2.0, offset=-1.0)(inputs)\n",
        "\n",
        "base_model = ResNet50V2(weights='imagenet', include_top=False, input_tensor=x)\n",
        "\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "# Build Classifier Head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "predictions = Dense(1, activation=None)(x) # Logits output for numerical stability\n",
        "\n",
        "resnet_model = Model(inputs=inputs, outputs=predictions)"
      ],
      "metadata": {
        "id": "s6fmxoNU4GLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Compile and Train\n",
        "We define the callbacks to save the best weights specifically for this architecture (best_resnet_320.h5) and run the training process using the existing 320x320 data generators."
      ],
      "metadata": {
        "id": "dBqfJmUA4h48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(\n",
        "    optimizer=SGD(learning_rate=1e-4, momentum=0.9, clipnorm=1.0),\n",
        "    loss=BinaryCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks_resnet = [\n",
        "\n",
        "    ModelCheckpoint('best_resnet_320.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "history_resnet = resnet_model.fit(\n",
        "    train_generator_320,\n",
        "    epochs=25,\n",
        "    validation_data=validation_generator_320,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=callbacks_resnet,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "2HjBy0Cl4j36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Setup Data & Configuration\n",
        "We need to ensure the validation data is loaded exactly the same way as during training to guarantee a fair evaluation. We re-create the dataframe split using the same random seed."
      ],
      "metadata": {
        "id": "0Fjy6D2F49dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if Path('/kaggle/working/train_png_converted').exists():\n",
        "    PNG_DIR = Path('/kaggle/working/train_png_converted')\n",
        "else:\n",
        "    PNG_DIR = Path('/kaggle/input/rsna-pneu-train-png/orig')\n",
        "\n",
        "\n",
        "labels_path = Path('/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_labels.csv')\n",
        "df_labels = pd.read_csv(labels_path)\n",
        "\n",
        "df_class = df_labels.drop_duplicates('patientId')[['patientId', 'Target']].copy()\n",
        "df_class['filename'] = df_class['patientId'].apply(lambda x: f\"{x}.png\")\n",
        "df_class['Target'] = df_class['Target'].astype(str)\n",
        "\n",
        "train_df, val_df = train_test_split(df_class, test_size=0.2, random_state=42, stratify=df_class['Target'])\n",
        "\n",
        "print(f\"Validation set size: {len(val_df)}\")"
      ],
      "metadata": {
        "id": "30jlGmIX49x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load ResNet Model & Run TTA Prediction\n",
        "We load the best_resnet_320.h5 model file. Then, we run 5-Pass Test Time Augmentation. This means we predict on the validation set 5 times, applying random augmentations (flips, zooms) each time, and average the results. This mimics how the ensemble will eventually work and gives a better estimate of the model"
      ],
      "metadata": {
        "id": "PSuTkgTw5Cv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = load_model('best_resnet_320.h5', compile=False\n",
        "\n",
        "\n",
        "\n",
        "tta_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "\n",
        "\n",
        "tta_generator = tta_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=PNG_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='Target',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "preds_list = []\n",
        "for i in range(5):\n",
        "    print(f\"  > Pass {i+1}/5...\")\n",
        "    tta_generator.reset()\n",
        "    logits = resnet_model.predict(tta_generator, verbose=0)\n",
        "    preds_list.append(tf.sigmoid(logits).numpy())\n",
        "\n",
        "resnet_preds = np.mean(preds_list, axis=0)\n",
        "y_true = tta_generator.classes\n",
        "y_pred_binary = (resnet_preds > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "tCc4BWvC5V1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics Report & Visualization\n",
        "Finally, we calculate the standard classification metrics (Accuracy, AUC, Sensitivity, Specificity) and visualize the performance using a Confusion Matrix and ROC Curve."
      ],
      "metadata": {
        "id": "TPhkAuPg5wiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_true, y_pred_binary)\n",
        "auc = roc_auc_score(y_true, resnet_preds)\n",
        "cm = confusion_matrix(y_true, y_pred_binary)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "precision = tp / (tp + fp)\n",
        "f1 = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(f\" RESNET50V2 MODEL REPORT\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\" Accuracy:       {acc * 100:.2f}%\")\n",
        "print(f\"AUC Score:      {auc:.4f}\")\n",
        "print(f\"----------------------------------------\")\n",
        "print(f\" Sensitivity:    {sensitivity * 100:.2f}%\")\n",
        "print(f\"Specificity:    {specificity * 100:.2f}%\")\n",
        "print(f\" F1 Score:       {f1:.4f}\")\n",
        "print(f\"{'='*40}\\n\")\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', cbar=False,\n",
        "            xticklabels=['Normal', 'Pneumonia'],\n",
        "            yticklabels=['Normal', 'Pneumonia'])\n",
        "plt.title('ResNet Confusion Matrix', fontsize=14)\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_true, resnet_preds)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(fpr, tpr, color='green', lw=3, label=f'ResNet AUC = {auc:.4f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ResNet ROC Curve', fontsize=14)\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j28wGtjo50ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Ensemble Members\n",
        "We load both trained models. The DenseNet121 serves as our primary expert (higher individual accuracy), while the ResNet50V2 acts as a partner to catch edge cases the DenseNet might miss."
      ],
      "metadata": {
        "id": "jc5P_mc-6lRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    model_dense = load_model('best_320_densenet.h5', compile=False)\n",
        "    print(\"DenseNet121 (Expert) Loaded.\")\n",
        "\n",
        "    model_resnet = load_model('best_resnet_320.h5', compile=False)\n",
        "    print(\" ResNet50V2 (Partner) Loaded.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Error loading models: {e}\")"
      ],
      "metadata": {
        "id": "bIAnlOjw6ufL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Perform Test Time Augmentation (TTA)\n",
        "Instead of a single prediction, we predict on the validation set 5 times for each model, applying random augmentations (zoom, rotation) each time. We then average these predictions. This statistically reduces the likelihood of a model making a mistake due to image orientation or artifacts."
      ],
      "metadata": {
        "id": "NT4IDkDM6_eD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tta_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "\n",
        "tta_generator = tta_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=PNG_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='Target',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "NUM_TTA = 5\n",
        "preds_dense_list = []\n",
        "preds_resnet_list = []\n",
        "\n",
        "for i in range(NUM_TTA):\n",
        "    print(f\"   > Pass {i+1}/{NUM_TTA}...\")\n",
        "    tta_generator.reset()\n",
        "\n",
        "    p1 = model_dense.predict(tta_generator, verbose=1)\n",
        "    preds_dense_list.append(tf.sigmoid(p1).numpy())\n",
        "\n",
        "\n",
        "    p2 = model_resnet.predict(tta_generator, verbose=1)\n",
        "    preds_resnet_list.append(tf.sigmoid(p2).numpy())\n",
        "\n",
        "\n",
        "avg_pred_dense = np.mean(preds_dense_list, axis=0)\n",
        "avg_pred_resnet = np.mean(preds_resnet_list, axis=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "oZRLgsvB6_LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Ensemble Aggregation:\n",
        "We combine the predictions using a Weighted Average. We assign a weight of 0.6 to the DenseNet (better performance) and 0.4 to the ResNet."
      ],
      "metadata": {
        "id": "lmllJl7Z7LM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weighted Ensemble\n",
        "final_ensemble_preds = (avg_pred_dense * 0.6) + (avg_pred_resnet * 0.4)\n",
        "\n",
        "# Extract Ground Truth labels\n",
        "y_true = tta_generator.classes"
      ],
      "metadata": {
        "id": "hainYcIQ7Nbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Threshold Optimization & Metrics:\n",
        "We dynamically scan thresholds from 0.0 to 1.0 to find the specific cutoff that maximizes accuracy. This is often better than using the default 0.5 threshold for imbalanced medical datasets."
      ],
      "metadata": {
        "id": "MftcxzaU7Wda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.arange(0.0, 1.0, 0.01)\n",
        "accuracies = []\n",
        "\n",
        "# Test every threshold\n",
        "for t in thresholds:\n",
        "    y_temp = (final_ensemble_preds > t).astype(int)\n",
        "    acc = accuracy_score(y_true, y_temp)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "best_idx = np.argmax(accuracies)\n",
        "best_threshold = thresholds[best_idx]\n",
        "best_acc = accuracies[best_idx]\n",
        "\n",
        "ensemble_auc = roc_auc_score(y_true, final_ensemble_preds)\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\" Ensemble AUC Score:        {ensemble_auc:.4f}\")\n",
        "print(f\" Optimized Accuracy:        {best_acc * 100:.2f}%\")\n",
        "print(f\" (at Threshold: {best_threshold:.2f})\")\n",
        "print(f\"{'='*40}\\n\")"
      ],
      "metadata": {
        "id": "AkmLlO_g7ZJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Visualization\n",
        "Finally, we plot the ROC Curve (to show diagnostic ability) and the Confusion Matrix (at the optimized threshold) to visualize false positives vs. false negatives."
      ],
      "metadata": {
        "id": "ik64Z5VG7i3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, final_ensemble_preds)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(fpr, tpr, color='purple', lw=3, label=f'Ensemble AUC = {ensemble_auc:.4f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Ensemble ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "y_pred_best = (final_ensemble_preds > best_threshold).astype(int)\n",
        "cm = confusion_matrix(y_true, y_pred_best)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=['Normal', 'Pneumonia'],\n",
        "            yticklabels=['Normal', 'Pneumonia'])\n",
        "plt.title(f'Confusion Matrix (Threshold {best_threshold:.2f})')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Abttameo7kJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Domain Adaptation: Fine-Tuning on Adult X-rays (NIH)\n",
        "Our DenseNet model is currently an expert on children's X-rays. To make it robust for adults, we will fine-tune it using the NIH Chest X-ray Dataset. We use a very low learning rate to gently introduce adult anatomical features without forgetting the pneumonia features it has already learned."
      ],
      "metadata": {
        "id": "6XmcS-qz8L-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NIH_CSV = None\n",
        "NIH_IMG_DIR = None\n",
        "MODEL_PATH = None\n",
        "\n",
        "for root, dirs, files in os.walk('/kaggle/input'):\n",
        "    if 'sample_labels.csv' in files:\n",
        "        NIH_CSV = os.path.join(root, 'sample_labels.csv')\n",
        "        if 'images' in dirs:\n",
        "            NIH_IMG_DIR = os.path.join(root, 'images')\n",
        "        else:\n",
        "            NIH_IMG_DIR = root\n",
        "\n",
        "\n",
        "    if 'best_320_densenet.h5' in files:\n",
        "        MODEL_PATH = os.path.join(root, 'best_320_densenet.h5')\n",
        "\n",
        "if not NIH_CSV:\n",
        "    print(\"\\n Could not find\")\n",
        "    raise FileNotFoundError(\"Missing Dataset\")\n",
        "else:\n",
        "    print(f\"Found Data\")\n",
        "\n",
        "if not MODEL_PATH:\n",
        "    print(\"\\nCould not find 'best_320_densenet.h5'.\")\n",
        "    if os.path.exists('best_320_densenet.h5'):\n",
        "        MODEL_PATH = 'best_320_densenet.h5'\n",
        "        print(f\" Found model in working directory: {MODEL_PATH}\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Missing Model\")\n",
        "else:\n",
        "    print(f\" Found Model: {MODEL_PATH}\")"
      ],
      "metadata": {
        "id": "yX0EoKey8QiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Processing\n",
        "The NIH dataset labels are more complex than the pediatric one. We filter the data to strictly separate \"Pneumonia\" cases from \"No Finding\" (Normal) cases, ignoring other diseases for this specific binary classifier."
      ],
      "metadata": {
        "id": "_uA2KKm38lx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(NIH_CSV)\n",
        "\n",
        "def get_label(labels):\n",
        "    if 'Pneumonia' in labels: return 'PNEUMONIA'\n",
        "    if labels == 'No Finding': return 'NORMAL'\n",
        "    return 'OTHER'\n",
        "\n",
        "df['class'] = df['Finding Labels'].apply(get_label)\n",
        "df_adult = df[df['class'] != 'OTHER'].copy()\n",
        "\n",
        "train_df, val_df = train_test_split(df_adult, test_size=0.2, random_state=42, stratify=df_adult['class'])\n",
        "print(f\"Found {len(df_adult)} valid images. Training on {len(train_df)}.\")"
      ],
      "metadata": {
        "id": "KzzblXKa8u16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generators & TrainingWe initialize the generators with the same high resolution ($320 \\times 320$) used previously. Then, we load the pediatric model and train it for a few epochs on the adult data using SGD with a low learning rate (1e-5) to ensure stable convergence."
      ],
      "metadata": {
        "id": "Hp9wcTw68yJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, rotation_range=10, zoom_range=0.1, horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df, directory=NIH_IMG_DIR, x_col='Image Index', y_col='class',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df, directory=NIH_IMG_DIR, x_col='Image Index', y_col='class',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='binary', shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "model = load_model(MODEL_PATH, compile=False)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=SGD(learning_rate=1e-5, momentum=0.9, clipnorm=1.0),\n",
        "    loss=BinaryCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint('best_universal_densenet.h5', monitor='val_loss', save_best_only=True, mode='min'),\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "L0vVRskN812a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Locate Dataset & Model :\n",
        "This block automatically searches the Kaggle directories to find the NIH dataset CSV, image folder, and your trained model file (best_universal_densenet.h5)."
      ],
      "metadata": {
        "id": "q9WMlHHz9a5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NIH_CSV = None\n",
        "NIH_IMG_DIR = None\n",
        "MODEL_PATH = None\n",
        "\n",
        "for root, dirs, files in os.walk('/kaggle/input'):\n",
        "    if 'sample_labels.csv' in files:\n",
        "        NIH_CSV = os.path.join(root, 'sample_labels.csv')\n",
        "        NIH_IMG_DIR = os.path.join(root, 'images') if 'images' in dirs else root\n",
        "    if 'best_universal_densenet.h5' in files:\n",
        "        MODEL_PATH = os.path.join(root, 'best_universal_densenet.h5')\n",
        "\n",
        "if not MODEL_PATH and os.path.exists('best_universal_densenet.h5'):\n",
        "    MODEL_PATH = 'best_universal_densenet.h5'\n",
        "\n",
        "if not NIH_CSV or not MODEL_PATH:\n",
        "    print(f\"\\nData: {NIH_CSV}\\nModel: {MODEL_PATH}\")\n",
        ""
      ],
      "metadata": {
        "id": "vbHppPuf-Dnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation:\n",
        "We filter the NIH dataset to keep only \"Pneumonia\" and \"Normal\" (No Finding) cases. Crucially, we perform the exact same split (with random_state=42) used during training to regenerate the Validation Set—data the model has never trained on."
      ],
      "metadata": {
        "id": "-Er_ykAz-NTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(NIH_CSV)\n",
        "\n",
        "def get_label(labels):\n",
        "    if 'Pneumonia' in labels: return 'PNEUMONIA'\n",
        "    if labels == 'No Finding': return 'NORMAL'\n",
        "    return 'OTHER'\n",
        "\n",
        "df['class'] = df['Finding Labels'].apply(get_label)\n",
        "df_adult = df[df['class'] != 'OTHER'].copy()\n",
        "\n",
        "val_df = train_test_split(df_adult, test_size=0.2, random_state=42, stratify=df_adult['class'])"
      ],
      "metadata": {
        "id": "5HSuMzT3-Sqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Inference :\n",
        "We create a data generator for the validation set and run the model to get probability predictions"
      ],
      "metadata": {
        "id": "QL7-ZhyV-bSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=NIH_IMG_DIR,\n",
        "    x_col='Image Index',\n",
        "    y_col='class',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "model = load_model(MODEL_PATH, compile=False)\n",
        "\n",
        "val_generator.reset()\n",
        "logits = model.predict(val_generator, verbose=1)\n",
        "probs = tf.sigmoid(logits).numpy()"
      ],
      "metadata": {
        "id": "e5GlMmxM-brq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We evaluate the model using standard metrics: Accuracy, AUC, Sensitivity (Recall), and Specificity."
      ],
      "metadata": {
        "id": "XE0Z49Mk-Rnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = val_generator.classes\n",
        "\n",
        "y_pred = (probs > 0.5).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "auc = roc_auc_score(y_true, probs)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(f\" UNIVERSAL MODEL RESULTS (ADULTS)\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\" Accuracy:       {acc * 100:.2f}%\")\n",
        "print(f\"AUC Score:      {auc:.4f}\")\n",
        "print(f\"----------------------------------------\")\n",
        "print(f\" Sensitivity:    {sensitivity * 100:.2f}% (Caught Pneumonia)\")\n",
        "print(f\" Specificity:    {specificity * 100:.2f}% (Cleared Normal)\")\n",
        "print(f\"{'='*40}\\n\")"
      ],
      "metadata": {
        "id": "PJBZiA0z-lXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we plot the Confusion Matrix to see exact error counts and the ROC Curve to visualize the trade-off between sensitivity and false positives."
      ],
      "metadata": {
        "id": "h7YAh76c-s0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
        "plt.title('Confusion Matrix (Adults)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.xticks([0.5, 1.5], ['Normal', 'Pneumonia'])\n",
        "plt.yticks([0.5, 1.5], ['Normal', 'Pneumonia'])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "fpr, tpr, _ = roc_curve(y_true, probs)\n",
        "plt.plot(fpr, tpr, color='green', lw=3, label=f'AUC = {auc:.4f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r5ChcgnH-tUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Universal Training on CheXpert"
      ],
      "metadata": {
        "id": "pHHMLnNP_OLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell sets up the environment and specifically looks for your previously trained best_universal_densenet.h5. It also defines the paths for the CheXpert dataset, which has a unique directory structure on Kaggle."
      ],
      "metadata": {
        "id": "VXdFC4BL_Yw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 16\n",
        "OLD_MODEL_NAME = 'best_universal_densenet.h5'\n",
        "NEW_MODEL_NAME = 'best_chexpert_densenet.h5'\n",
        "\n",
        "DATA_ROOT = Path('/kaggle/input/chexpert')\n",
        "CSV_PATH = DATA_ROOT / 'train.csv'\n",
        "\n",
        "MODEL_PATH = None\n",
        "possible_paths = [\n",
        "    Path(f'/kaggle/input/my-pneumonia-model/{OLD_MODEL_NAME}'),\n",
        "    Path(OLD_MODEL_NAME),\n",
        "    Path(f'/kaggle/working/{OLD_MODEL_NAME}')\n",
        "]\n",
        "\n",
        "for p in possible_paths:\n",
        "    if p.exists():\n",
        "        MODEL_PATH = p\n",
        "        print(f\"Found previous model at: {MODEL_PATH}\")\n",
        "        break\n",
        "\n",
        "if not MODEL_PATH:\n",
        "    print(f\" Could not find old model.)"
      ],
      "metadata": {
        "id": "a0_6n_JS_Xsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning & Path Fixing:\n",
        "The CheXpert CSV file contains relative paths (e.g., CheXpert-v1.0-small/train/...) that do not match the Kaggle input directory structure. This cell fixes those paths and filters the dataset to only include Pneumonia (Positive) and No Finding (Normal) cases."
      ],
      "metadata": {
        "id": "UNrSTFjc_pds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "def get_label(row):\n",
        "    if row['Pneumonia'] == 1.0: return 'PNEUMONIA'\n",
        "    if row['No Finding'] == 1.0: return 'NORMAL'\n",
        "    return 'OTHER'\n",
        "\n",
        "df['class'] = df.apply(get_label, axis=1)\n",
        "df_clean = df[df['class'] != 'OTHER'].copy()\n",
        "\n",
        "def fix_path_exact(p):\n",
        "    if 'train/' in p:\n",
        "        idx = p.find('train/')\n",
        "        relative_path = p[idx:] #\n",
        "        return str(DATA_ROOT / relative_path)\n",
        "    return str(p)\n",
        "\n",
        "df_clean['path_fixed'] = df_clean['Path'].apply(fix_path_exact)\n",
        "\n",
        "if os.path.exists(df_clean['path_fixed'].iloc[0]):\n",
        "    print(f\" Path check passed! Example: {df_clean['path_fixed'].iloc[0]}\")\n",
        "else:\n",
        "    print(f\" Path check FAILED: {df_clean['path_fixed'].iloc[0]}\")\n",
        "\n",
        "if len(df_clean) > 50000:\n",
        "    df_clean = df_clean.sample(50000, random_state=42)\n",
        "\n",
        "train_df, val_df = train_test_split(df_clean, test_size=0.1, random_state=42, stratify=df_clean['class'])\n",
        "print(f\"Training on {len(train_df)} images\")"
      ],
      "metadata": {
        "id": "CtCVVsVw_SMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Generators :\n",
        "We create the data generators using the fixed paths. Note that we use validate_filenames=False to speed up initialization, since we manually verified the paths in the previous step."
      ],
      "metadata": {
        "id": "8Cguzi7M_1bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='path_fixed',\n",
        "    y_col='class',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    validate_filenames=False\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='path_fixed',\n",
        "    y_col='class',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False,\n",
        "    validate_filenames=False\n",
        ")"
      ],
      "metadata": {
        "id": "E0g-0b5T_2vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-Tune on CheXpert :\n",
        "We load the previous best model and train it on the new data. We use a very low learning rate (1e-5) to ensure the model adapts to the new data source (CheXpert) without forgetting what it learned from the previous datasets (NIH and Pediatric)."
      ],
      "metadata": {
        "id": "dLEzR46Q_6Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_PATH:\n",
        "    print(f\"\\n📥 Loading {OLD_MODEL_NAME}...\")\n",
        "    model = load_model(MODEL_PATH, compile=False)\n",
        "else:\n",
        "\n",
        "    from tensorflow.keras.applications import DenseNet121\n",
        "    from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "    base = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = base.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    pred = Dense(1, activation=None)(x)\n",
        "    model = Model(inputs=base.input, outputs=pred)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=SGD(learning_rate=1e-5, momentum=0.9, clipnorm=1.0),\n",
        "    loss=BinaryCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(NEW_MODEL_NAME, monitor='val_loss', save_best_only=True, mode='min'),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "_efi9mYL_9G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Threshold Optimization\n",
        "Instead of using a default threshold of 0.5, we loop through values from 0.0 to 1.0 to find the specific cutoff that maximizes the model's accuracy."
      ],
      "metadata": {
        "id": "NJY40X6zB5S6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = test_generator.classes\n",
        "\n",
        "print(\"🔍 Finding Best Threshold...\")\n",
        "thresholds = np.arange(0.0, 1.0, 0.01)\n",
        "best_acc = 0\n",
        "best_thresh = 0.5\n",
        "\n",
        "for t in thresholds:\n",
        "    temp_preds = (probs > t).astype(int)\n",
        "\n",
        "    acc = accuracy_score(y_true, temp_preds)\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_thresh = t\n",
        "\n",
        "print(f\" Best Accuracy: {best_acc:.4f} at Threshold: {best_thresh:.2f}\")"
      ],
      "metadata": {
        "id": "oGMGK2lcCVwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Compute Clinical Metrics\n",
        "Once the best threshold is found, we generate the final binary predictions. We then use the Confusion Matrix to calculate Sensitivity (how well we detect Pneumonia) and Specificity (how well we ignore Normal cases), along with the AUC score."
      ],
      "metadata": {
        "id": "Fau79IyDCchM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_final = (probs > best_thresh).astype(int)\n",
        "\n",
        "final_auc = roc_auc_score(y_true, probs)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_final)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "precision = tp / (tp + fp)\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(f\" FINAL METRICS REPORT\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\" AUC Score:       {final_auc:.4f}\")\n",
        "print(f\"----------------------------------------\")\n",
        "print(f\" Sensitivity:     {sensitivity * 100:.2f}% (Recall)\")\n",
        "print(f\" Specificity:     {specificity * 100:.2f}% (True Neg Rate)\")\n",
        "print(f\" Precision:       {precision * 100:.2f}%\")\n",
        "print(f\"{'='*40}\\n\")"
      ],
      "metadata": {
        "id": "C2ZlgyOCCdNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Visualize Confusion Matrix\n",
        "This cell visualizes the results using the specific threshold derived above."
      ],
      "metadata": {
        "id": "g2T1UzdSClo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=['Normal', 'Pneumonia'],\n",
        "            yticklabels=['Normal', 'Pneumonia'])\n",
        "\n",
        "plt.title(f'Confusion Matrix (Threshold {best_thresh:.2f})')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-fUa9zB7CmUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detailed Metrics Report:\n",
        "This cell takes the predictions generated in the previous step and computes the performance statistics. Note that we manually calculate Specificity (the ability to correctly identify normal cases), as this is just as important as detecting pneumonia in a clinical setting."
      ],
      "metadata": {
        "id": "yErmhJqIDYUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_binary = (probs > THRESHOLD).astype(int)\n",
        "y_true_binary = y_true\n",
        "\n",
        "accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
        "sensitivity = recall_score(y_true_binary, y_pred_binary)\n",
        "precision = precision_score(y_true_binary, y_pred_binary)\n",
        "f1 = f1_score(y_true_binary, y_pred_binary)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_true_binary, y_pred_binary).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(f\"🩺  FINAL MODEL PERFORMANCE REPORT\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"Model:           DenseNet121 (Universal)\")\n",
        "print(f\"Threshold:       {THRESHOLD}\")\n",
        "print(f\"Test Set Size:   {len(y_true)} images\")\n",
        "print(f\"{'-'*40}\")\n",
        "print(f\" Accuracy:      {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"  F1-Score:      {f1:.4f}\")\n",
        "print(f\" AUC Score:     {roc_auc:.4f}\")\n",
        "print(f\"{'-'*40}\")\n",
        "print(f\" Sensitivity:   {sensitivity:.4f}  (Ability to detect Pneumonia)\")\n",
        "print(f\" Specificity:   {specificity:.4f}  (Ability to identify Normal)\")\n",
        "print(f\" Precision:     {precision:.4f}  (Trustworthiness of a positive prediction)\")\n",
        "print(f\"{'='*40}\\n\")\n",
        "\n",
        "print(\"Detailed Classification Report:\")\n",
        "print(classification_report(y_true_binary, y_pred_binary, target_names=['Normal', 'Pneumonia']))"
      ],
      "metadata": {
        "id": "pO1VCGHNDbXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Configuration & ImportsWe set up the environment and define thebest ($0.15$) that balances sensitivity and specificity for this  model."
      ],
      "metadata": {
        "id": "SM3-YR5kESzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 16\n",
        "THRESHOLD = 0.15\n",
        "MODEL_FILE = 'model.h5'"
      ],
      "metadata": {
        "id": "Ltksnnz5EX9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Locate Model & Data\n",
        "This block ensures we can find the model file (whether it's from the current session or an uploaded dataset) and sets up the paths for the test data."
      ],
      "metadata": {
        "id": "TtrFDD9UEcEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "possible_paths = [\n",
        "    Path(f'/kaggle/working/{MODEL_FILE}'),\n",
        "    Path(f'/kaggle/input/my-pneumonia-model/{MODEL_FILE}'),\n",
        "    Path(MODEL_FILE)\n",
        "]\n",
        "\n",
        "MODEL_PATH = None\n",
        "for p in possible_paths:\n",
        "    if p.exists():\n",
        "        MODEL_PATH = p\n",
        "        break\n",
        "\n",
        "if not MODEL_PATH:\n",
        "    print(f\" Error: Could not find '{MODEL_FILE}'\")\n",
        "    raise FileNotFoundError(\"Model file missing.\")\n",
        "\n",
        "print(f\" Found Model at: {MODEL_PATH}\")\n",
        "\n",
        "labels_path = Path('/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_labels.csv')\n",
        "\n",
        "if Path('/kaggle/working/train_png_converted').exists():\n",
        "    PNG_DIR = Path('/kaggle/working/train_png_converted')\n",
        "else:\n",
        "    PNG_DIR = Path('/kaggle/input/rsna-pneu-train-png/orig')\n",
        "\n",
        "if not labels_path.exists():\n",
        "    raise FileNotFoundError(\" RSNA Dataset not found.\")"
      ],
      "metadata": {
        "id": "ATOdQOIyEd2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Prepare Test Data\n",
        "We reconstruct the data split to isolate the Validation Set (20%). This ensures we are evaluating the model on data it has never seen during training."
      ],
      "metadata": {
        "id": "-XjtOWp4Epyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_labels = pd.read_csv(labels_path)\n",
        "df_class = df_labels.drop_duplicates('patientId')[['patientId', 'Target']].copy()\n",
        "df_class['filename'] = df_class['patientId'].apply(lambda x: f\"{x}.png\")\n",
        "df_class['Target'] = df_class['Target'].astype(str)\n",
        "\n",
        "val_df = train_test_split(df_class, test_size=0.2, random_state=42, stratify=df_class['Target'])\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=PNG_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='Target',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "TC-P4XXsEqO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Load Model & Predict\n",
        "We load the trained DenseNet model and generate probability predictions for every image in the validation set."
      ],
      "metadata": {
        "id": "gi5X50TSEwKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(MODEL_PATH, compile=False)\n",
        "\n",
        "logits = model.predict(val_generator, verbose=1)\n",
        "probs = tf.sigmoid(logits).numpy()\n",
        "y_true = val_generator.classes\n",
        "\n"
      ],
      "metadata": {
        "id": "diRXXbHIEwyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Generate Metrics & Charts\n",
        "This final cell calculates the AUC score and generates two professional-grade plots:\n",
        "\n",
        "Confusion Matrix: Shows exactly how many Pneumonia cases were caught vs. missed at the chosen threshold.\n",
        "\n",
        "ROC Curve: Visualizes the model's diagnostic ability across all possible thresholds."
      ],
      "metadata": {
        "id": "ObUXKvpxEz47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "y_pred = (probs > THRESHOLD).astype(int)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 16})\n",
        "plt.title(f'Confusion Matrix (Threshold {THRESHOLD})', fontsize=14)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.xticks([0.5, 1.5], ['Normal', 'Pneumonia'])\n",
        "plt.yticks([0.5, 1.5], ['Normal', 'Pneumonia'])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=3, label=f'AUC = {roc_auc:.4f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve', fontsize=14)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xw7DbFhVE1ls"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}